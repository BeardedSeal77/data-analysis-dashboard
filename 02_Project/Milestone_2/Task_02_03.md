# HDPSA BIN381 – Task 3 Pipeline (3A + 2 + 3B)

## Purpose

This pipeline implements the **Data Cleaning and Analysis phase** of CRISP-DM for the **HDPSA national datasets** (13 CSV files). It ensures that the data is reliable, consistent, and ready for modeling.

The pipeline follows three main stages:

1. **Task 3A – Simple Cleanup**
2. **Task 2 – Full Analysis on Clean Data**
3. **Task 3B – Advanced Cleanup Based on Task 2 Findings**


---

## Folder Structure

When you run the R, it creates the following structure under `02_Project/Milestone_2/`:

```
02_Project/Milestone_2/
 ├── Task_03A_Simple_Cleanup/
 │    ├── cleaned/     # cleaned datasets after basic cleanup
 │    ├── logs/        # logs of actions (columns dropped, duplicates removed, etc.)
 │    └── visuals/     # optional basic plots
 │
 ├── Task_02_Analysis/
 │    ├── correlation/ # correlation matrices (PNG + CSV)
 │    ├── significance/# ANOVA/t-test results
 │    ├── pca/         # PCA plots + RDS objects
 │    ├── importance/  # feature importance scores
 │    └── selection/   # field selection tables (keep/drop)
 │
 └── Task_03B_Advanced_Cleanup/
      ├── cleaned_final/ # advanced cleaned datasets ready for modeling
      ├── logs/          # logs of advanced cleanup decisions
      ├── imputed/       # (optional) imputed versions
      └── visuals/       # post-cleanup diagnostics
```

---

## How the Code Works

### **1. Task 3A – Simple Cleanup**

* **Drop completely empty fields**
* **Remove duplicate rows**
* **Handle obvious outliers** by capping numeric values at the 1st and 99th percentiles
* **Convert numeric-looking columns** to numeric type
* **Standardize field names** with `janitor::clean_names()`
* **Basic missing value imputation**

  * Numeric → median
  * Categorical → mode

**Result:** Clean, consistent datasets saved in `Task_03A_Simple_Cleanup/cleaned`.

---

### **2. Task 2 – Full Analysis on Clean Data**

* **Correlation Analysis**: Pearson correlations (numeric variables only) with heatmap + CSV matrix
* **Statistical Significance Tests**: ANOVA (numeric \~ categorical combinations)
* **PCA**: Dimensionality reduction + scree/variable plots
* **Feature Importance Ranking**: Information gain (if `value` column present)
* **Field Selection Table**: Each variable marked `keep` or `drop` based on missingness %

**Result:** A full **data quality report** stored across the `Task_02_Analysis` subfolders.

---

### **3. Task 3B – Advanced Cleanup**

* **Drop fields** flagged as “drop” in Task 2
* **Advanced Missing Value Imputation** using **MICE (Predictive Mean Matching)**

  * Falls back to mean imputation if MICE fails
* **Sophisticated Outlier Handling** (optionally add z-score winsorization)
* **Noise Reduction** by excluding irrelevant fields

**Result:** Final datasets ready for modeling in `Task_03B_Advanced_Cleanup/cleaned_final`.

---

## How to Run

1. Place your raw datasets in:

   ```
   E:/data-analysis-dashboard/02_Project/Data/01_Raw
   ```
2. Open **Positron** or **RStudio**.
3. Knit the R Markdown file:

   * Open `task3_pipeline.Rmd`
   * Click **Knit → PDF**
   * This generates:

     * A **PDF report** with inline examples (plots/tables)
     * All **cleaned datasets + logs + analysis** in the output folders

---

## Deliverables

Running this pipeline produces:

* **PDF report** (documentation + sample results)
* **Intermediate datasets** (Task 3A cleaned)
* **Analysis outputs** (Task 2 correlations, PCA, importance, etc.)
* **Final datasets** (Task 3B advanced cleaned, modeling-ready)
* **Logs** documenting what was dropped, imputed, or changed
