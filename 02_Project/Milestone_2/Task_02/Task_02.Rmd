---
title: 'Task 2: Verify Data Quality - Statistical Validation and Field Selection'
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  word_document:
    toc: true
    number_sections: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
                      out.width = "100%", fig.pos = "H")
suppressPackageStartupMessages({
  library(tidyverse)
  library(readr)
  library(janitor)
  library(corrplot)
  library(psych)
  library(factoextra)
  library(VIM)
  library(car)
  library(moments)
  library(gt)
})
theme_set(theme_minimal())


```

# 1. Data Preparation & Standardization

## 1.0 Setup Global Variables

```{r global_variables}
# Auto-detect environment and set paths
current_dir <- basename(getwd())
if (current_dir == "Task_02") {
  # Running in RStudio (current directory is Task_02)
  base_path <- "../../Data/01_Raw"
  outputs_path <- "outputs"
  cat("Environment: RStudio\n")
} else {
  # Running in VS Code (from project root)
  base_path <- "02_Project/Data/01_Raw"
  outputs_path <- "02_Project/Milestone_2/Task_02/outputs"
  cat("Environment: VS Code\n")
}

# Create outputs directory
if (!dir.exists(outputs_path)) {
  dir.create(outputs_path, recursive = TRUE)
  cat("Created outputs directory:", outputs_path, "\n")
}

# Quality thresholds
MISSING_THRESHOLD <- 0.5      # 50% missing data
OUTLIER_THRESHOLD <- 0.05     # 5% outliers
LOW_VARIANCE_THRESHOLD <- 0.01 # CV < 0.01

cat("Global variables set successfully\n")
cat("Base path:", base_path, "\n")
cat("Outputs path:", outputs_path, "\n")
```

```{r directory_structure}
# Check if directory exists and show contents
if (dir.exists(base_path)) {
  cat("Directory exists:", base_path, "\n\n")

  # List all files and folders in the directory
  all_items <- list.files(base_path, full.names = FALSE)
  cat("Contents of", base_path, ":\n")

  if (length(all_items) > 0) {
    for (item in all_items) {
      item_path <- file.path(base_path, item)
      if (dir.exists(item_path)) {
        cat("  [DIR]  ", item, "\n")
      } else {
        cat("  [FILE] ", item, "\n")
      }
    }
  } else {
    cat("  Directory is empty\n")
  }
} else {
  cat("Directory does not exist:", base_path, "\n")
}
```

## 1.1 Load All Datasets

```{r load_data}
# List all CSV files
csv_files <- list.files(base_path, pattern = "\\.csv$", full.names = TRUE)
cat("Found", length(csv_files), "CSV files:\n")
for(file in csv_files) {
  cat("- ", basename(file), "\n")
}

# Function to read CSV with proper header handling
read_csv_clean <- function(path) {
  # Read the first line to get proper column names
  headers <- readr::read_lines(path, n_max = 1)
  col_names <- unlist(strsplit(headers, ","))

  # Skip the metadata line (line 2) and read with proper headers
  readr::read_csv(path, show_col_types = FALSE, skip = 2, col_names = col_names) %>%
    janitor::clean_names()
}

# Load all datasets
datasets <- map(csv_files, read_csv_clean)
names(datasets) <- tools::file_path_sans_ext(basename(csv_files))

# Remove any datasets with no rows
datasets <- datasets[map_int(datasets, nrow) > 0]

cat("\nLoaded", length(datasets), "datasets with data\n")
```

## 1.2 Standardize Field Structure

```{r standardize_fields}
# Get all unique column names across datasets
all_columns <- unique(unlist(map(datasets, names)))
cat("Total unique columns across all datasets:", length(all_columns), "\n")

# Identify core fields present in all datasets
common_fields <- Reduce(intersect, map(datasets, names))
cat("Common fields in all datasets:", length(common_fields), "\n")
print(common_fields)

# Dynamically categorize fields by analyzing their actual data types and content
sample_dataset <- datasets[[1]]  # Use first dataset as reference

# Define expected numeric fields based on data dictionary
expected_numeric_fields <- c("value", "precision", "survey_year", "indicator_order",
                            "characteristic_order", "denominator_weighted",
                            "denominator_unweighted", "ci_low", "ci_high", "level_rank")

# Detect numeric fields - combine expected fields with actual numeric detection
numeric_fields <- names(sample_dataset)[sapply(sample_dataset, function(x) {
  # Check if it's already numeric
  if (is.numeric(x)) return(TRUE)

  # Check if it's character but contains only numeric values (including decimals and negatives)
  if (is.character(x)) {
    non_na_values <- x[!is.na(x) & x != ""]
    if (length(non_na_values) == 0) return(FALSE)
    return(all(grepl("^-?[0-9]*\\.?[0-9]+([eE][+-]?[0-9]+)?$", non_na_values, perl = TRUE)))
  }

  return(FALSE)
})]

# Also include any expected numeric fields that might be in the data
numeric_fields <- unique(c(numeric_fields,
                          intersect(tolower(names(sample_dataset)), expected_numeric_fields),
                          intersect(names(sample_dataset), expected_numeric_fields)))

# Detect logical/boolean fields
expected_logical_fields <- c("is_total", "is_preferred")
logical_fields <- names(sample_dataset)[sapply(sample_dataset, function(x) {
  if (is.logical(x)) return(TRUE)
  if (is.character(x)) {
    non_na_values <- tolower(x[!is.na(x) & x != ""])
    if (length(non_na_values) == 0) return(FALSE)
    return(all(non_na_values %in% c("true", "false", "t", "f", "yes", "no", "1", "0")))
  }
  return(FALSE)
})]

# Also include expected logical fields
logical_fields <- unique(c(logical_fields,
                          intersect(tolower(names(sample_dataset)), expected_logical_fields),
                          intersect(names(sample_dataset), expected_logical_fields)))

# All remaining fields are categorical
categorical_fields <- setdiff(names(sample_dataset), c(numeric_fields, logical_fields))

cat("\nDynamic field categorization:\n")
cat("Numeric fields (", length(numeric_fields), "):", paste(numeric_fields, collapse = ", "), "\n")
cat("Logical fields (", length(logical_fields), "):", paste(logical_fields, collapse = ", "), "\n")
cat("Categorical fields (", length(categorical_fields), "):", paste(categorical_fields, collapse = ", "), "\n")

# Create standardized dataset summary
dataset_summary <- map_dfr(datasets, function(df) {
  tibble(
    total_rows = nrow(df),
    total_cols = ncol(df),
    numeric_cols = sum(names(df) %in% numeric_fields),
    categorical_cols = sum(names(df) %in% categorical_fields),
    logical_cols = sum(names(df) %in% logical_fields),
    missing_cells = sum(is.na(df)),
    missing_pct = round(100 * sum(is.na(df)) / (nrow(df) * ncol(df)), 2)
  )
}, .id = "dataset")

# Display summary
gt(dataset_summary) %>%
  tab_header(title = "Standardized Dataset Summary")

# Export summary
write_csv(dataset_summary, file.path(outputs_path, "standardized_datasets_summary.csv"))
cat("Exported:", file.path(outputs_path, "standardized_datasets_summary.csv"), "\n")
```

# 2. Field Quality Assessment

## 2.1 Comprehensive Field Quality Analysis

```{r field_quality_assessment}
# Function to assess field quality across multiple dimensions
assess_field_quality <- function(df, dataset_name) {
  all_cols <- names(df)

  map_dfr(all_cols, function(col) {
    values <- df[[col]]
    non_missing <- values[!is.na(values)]

    # Basic metrics
    total_count <- length(values)
    missing_count <- sum(is.na(values))
    missing_rate <- missing_count / total_count
    unique_count <- length(unique(non_missing))
    unique_rate <- unique_count / length(non_missing)

    # Initialize result
    result <- tibble(
      dataset = dataset_name,
      field = col,
      total_count = total_count,
      missing_count = missing_count,
      missing_rate = missing_rate,
      unique_count = unique_count,
      unique_rate = unique_rate
    )

    # Field type classification
    is_numeric <- is.numeric(values)
    is_categorical <- !is_numeric

    if (is_numeric && length(non_missing) > 0) {
      # Numeric field quality metrics
      q25 <- quantile(non_missing, 0.25, na.rm = TRUE)
      q75 <- quantile(non_missing, 0.75, na.rm = TRUE)
      iqr <- q75 - q25
      outlier_threshold_low <- q25 - 1.5 * iqr
      outlier_threshold_high <- q75 + 1.5 * iqr
      outliers <- sum(non_missing < outlier_threshold_low | non_missing > outlier_threshold_high)
      outlier_rate <- outliers / length(non_missing)

      result <- result %>%
        mutate(
          field_type = "numeric",
          mean_value = mean(non_missing, na.rm = TRUE),
          std_dev = sd(non_missing, na.rm = TRUE),
          coefficient_of_variation = std_dev / abs(mean_value),
          skewness = moments::skewness(non_missing),
          kurtosis = moments::kurtosis(non_missing),
          outlier_count = outliers,
          outlier_rate = outlier_rate,
          min_value = min(non_missing, na.rm = TRUE),
          max_value = max(non_missing, na.rm = TRUE)
        )
    } else if (is_categorical && length(non_missing) > 0) {
      # Categorical field quality metrics
      value_counts <- table(non_missing)
      max_frequency <- max(value_counts)
      mode_frequency_rate <- max_frequency / length(non_missing)
      rare_categories <- sum(value_counts <= 5)
      cardinality_ratio <- unique_count / length(non_missing)

      result <- result %>%
        mutate(
          field_type = "categorical",
          mean_value = NA_real_,
          std_dev = NA_real_,
          coefficient_of_variation = NA_real_,
          skewness = NA_real_,
          kurtosis = NA_real_,
          outlier_count = NA_integer_,
          outlier_rate = NA_real_,
          max_frequency = max_frequency,
          mode_frequency_rate = mode_frequency_rate,
          rare_categories = rare_categories,
          cardinality_ratio = cardinality_ratio
        )
    } else {
      # Empty or all-missing field
      result <- result %>%
        mutate(
          field_type = ifelse(is_numeric, "numeric", "categorical"),
          mean_value = NA_real_,
          std_dev = NA_real_,
          coefficient_of_variation = NA_real_,
          skewness = NA_real_,
          kurtosis = NA_real_,
          outlier_count = NA_integer_,
          outlier_rate = NA_real_
        )
    }

    return(result)
  })
}

# Run field quality assessment on all datasets
field_quality_results <- map2_dfr(datasets, names(datasets), assess_field_quality)

# Summarize quality by field across datasets
field_quality_summary <- field_quality_results %>%
  group_by(field, field_type) %>%
  summarise(
    datasets_present = n(),
    avg_missing_rate = mean(missing_rate, na.rm = TRUE),
    avg_unique_rate = mean(unique_rate, na.rm = TRUE),
    avg_outlier_rate = mean(outlier_rate, na.rm = TRUE),
    avg_cv = mean(coefficient_of_variation, na.rm = TRUE),
    avg_skewness = mean(abs(skewness), na.rm = TRUE),
    high_cardinality_issues = sum(cardinality_ratio > 0.8, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(field_type, desc(avg_missing_rate))

gt(field_quality_summary %>% head(20)) %>%
  tab_header(title = "Field Quality Summary (Top 20 by Missing Rate)") %>%
  fmt_number(columns = c(avg_missing_rate, avg_unique_rate, avg_outlier_rate,
                        avg_cv, avg_skewness), decimals = 3)

# Export field quality results
write_csv(field_quality_results, file.path(outputs_path, "field_quality_assessment.csv"))
write_csv(field_quality_summary, file.path(outputs_path, "field_quality_summary.csv"))
cat("Exported: field quality assessment results\n")
```

## 2.2 Quality Issues Identification

```{r data_quality_issues}
# Function to flag data quality issues
flag_quality_issues <- function(field_quality_data) {
  field_quality_data %>%
    mutate(
      # Flag high missing data
      high_missing_flag = missing_rate > MISSING_THRESHOLD,

      # Flag excessive outliers (numeric fields only)
      excessive_outliers_flag = !is.na(outlier_rate) & outlier_rate > OUTLIER_THRESHOLD,

      # Flag low variance (numeric fields only)
      low_variance_flag = !is.na(coefficient_of_variation) &
                         coefficient_of_variation < LOW_VARIANCE_THRESHOLD,

      # Calculate total issue count per field
      total_issues = as.numeric(high_missing_flag) +
                    as.numeric(excessive_outliers_flag) +
                    as.numeric(low_variance_flag)
    ) %>%
    # Create overall quality rating
    mutate(
      quality_rating = case_when(
        total_issues == 0 ~ "Good Quality",
        total_issues == 1 ~ "Moderate Issues",
        total_issues >= 2 ~ "Significant Issues"
      )
    )
}

# Apply quality flagging
flagged_quality <- flag_quality_issues(field_quality_results)

# Summarize issues by field across all datasets
issue_summary_by_field <- flagged_quality %>%
  group_by(field, field_type) %>%
  summarise(
    datasets_present = n(),
    high_missing_datasets = sum(high_missing_flag),
    excessive_outliers_datasets = sum(excessive_outliers_flag, na.rm = TRUE),
    low_variance_datasets = sum(low_variance_flag, na.rm = TRUE),
    avg_issues_per_dataset = mean(total_issues),
    .groups = "drop"
  ) %>%
  arrange(desc(avg_issues_per_dataset), desc(high_missing_datasets))

gt(issue_summary_by_field %>% head(15)) %>%
  tab_header(title = "Data Quality Issues Summary by Field (Top 15 Problematic)") %>%
  fmt_number(columns = avg_issues_per_dataset, decimals = 2)

# Export quality issues data
write_csv(flagged_quality, file.path(outputs_path, "flagged_quality_issues.csv"))
write_csv(issue_summary_by_field, file.path(outputs_path, "quality_issues_by_field.csv"))
cat("Exported: data quality issues flagging results\n")
```

# 3. Cross-Dataset Correlation Analysis

## 3.1 Calculate Average Correlation Matrix

```{r correlation_analysis}
# Calculate correlation matrices for each dataset
all_correlations <- map2_dfr(datasets, names(datasets), function(df, dataset_name) {
  # Select numeric fields
  numeric_cols <- intersect(names(df), numeric_fields)
  numeric_data <- df %>% select(all_of(numeric_cols))

  # Convert to numeric and remove columns with no variance
  numeric_data <- numeric_data %>%
    mutate(across(everything(), as.numeric)) %>%
    select(where(function(x) {
      variance <- var(x, na.rm = TRUE)
      !is.na(variance) && variance > 0
    }))

  if (ncol(numeric_data) < 2) return(tibble())

  # Calculate correlation matrix
  cor_matrix <- cor(numeric_data, use = "pairwise.complete.obs")

  # Convert to long format
  as_tibble(cor_matrix, rownames = "field1") %>%
    pivot_longer(-field1, names_to = "field2", values_to = "correlation") %>%
    filter(field1 != field2) %>%
    mutate(dataset = dataset_name)
})

cat("Calculated correlations for", length(unique(all_correlations$dataset)), "datasets\n")

# Export all correlations
write_csv(all_correlations, file.path(outputs_path, "all_dataset_correlations.csv"))

# Create summary statistics across datasets
correlation_summary <- all_correlations %>%
  group_by(field1, field2) %>%
  summarise(
    datasets_present = n(),
    avg_correlation = mean(correlation, na.rm = TRUE),
    abs_avg_correlation = mean(abs(correlation), na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(datasets_present >= 2) %>%
  arrange(desc(abs_avg_correlation))

gt(correlation_summary %>% head(15)) %>%
  tab_header(title = "Top Field Correlations Across Datasets") %>%
  fmt_number(columns = c(avg_correlation, abs_avg_correlation), decimals = 3)

write_csv(correlation_summary, file.path(outputs_path, "correlation_summary.csv"))

# Field-level correlation rankings
field_rankings <- all_correlations %>%
  group_by(field1) %>%
  summarise(
    avg_abs_correlation = mean(abs(correlation), na.rm = TRUE),
    max_abs_correlation = max(abs(correlation), na.rm = TRUE),
    high_correlations_count = sum(abs(correlation) > 0.7, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(desc(avg_abs_correlation))

gt(field_rankings %>% head(10)) %>%
  tab_header(title = "Field Correlation Rankings") %>%
  fmt_number(columns = c(avg_abs_correlation, max_abs_correlation), decimals = 3)

write_csv(field_rankings, file.path(outputs_path, "field_correlation_rankings.csv"))

# High correlation pairs
high_corr_pairs <- all_correlations %>%
  filter(abs(correlation) > 0.8) %>%
  arrange(desc(abs(correlation)))

if (nrow(high_corr_pairs) > 0) {
  gt(high_corr_pairs %>% head(15)) %>%
    tab_header(title = "Highly Correlated Field Pairs (|r| > 0.8)") %>%
    fmt_number(columns = correlation, decimals = 3)

  write_csv(high_corr_pairs, file.path(outputs_path, "high_correlation_pairs.csv"))
}

cat("Exported correlation analysis results\n")
```

# 4. Feature Importance & Variance Analysis

## 4.1 Variance and Information Content Analysis

```{r variance_analysis}
# Function to calculate variance metrics for each dataset
calc_variance_metrics <- function(df, dataset_name) {
  numeric_cols <- intersect(names(df), numeric_fields)

  map_dfr(numeric_cols, function(col) {
    values <- df[[col]][!is.na(df[[col]])]

    if (length(values) < 2) {
      return(tibble(
        dataset = dataset_name,
        field = col,
        variance = NA,
        coefficient_of_variation = NA,
        range_normalized = NA,
        unique_values = length(unique(values)),
        information_content = NA
      ))
    }

    # Calculate various variance metrics
    var_val <- var(values)
    mean_val <- mean(values)
    cv <- if (mean_val != 0) sd(values) / abs(mean_val) else NA
    range_norm <- (max(values) - min(values)) / (abs(max(values)) + abs(min(values)) + 1e-10)
    unique_vals <- length(unique(values))

    # Information content (entropy-like measure)
    if (unique_vals > 1) {
      value_counts <- table(cut(values, breaks = min(unique_vals, 20)))
      proportions <- value_counts / sum(value_counts)
      proportions <- proportions[proportions > 0]
      info_content <- -sum(proportions * log2(proportions))
    } else {
      info_content <- 0
    }

    tibble(
      dataset = dataset_name,
      field = col,
      variance = var_val,
      coefficient_of_variation = cv,
      range_normalized = range_norm,
      unique_values = unique_vals,
      information_content = info_content
    )
  })
}

# Calculate variance metrics for all datasets
variance_results <- map2_dfr(datasets, names(datasets), calc_variance_metrics)

# Summarize variance by field
variance_summary <- variance_results %>%
  group_by(field) %>%
  summarise(
    datasets_analyzed = n(),
    avg_variance = mean(variance, na.rm = TRUE),
    avg_cv = mean(coefficient_of_variation, na.rm = TRUE),
    avg_range_norm = mean(range_normalized, na.rm = TRUE),
    avg_unique_values = mean(unique_values, na.rm = TRUE),
    avg_information_content = mean(information_content, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(desc(avg_information_content))

gt(variance_summary) %>%
  tab_header(title = "Feature Variance and Information Content Summary") %>%
  fmt_number(columns = c(avg_variance, avg_cv, avg_range_norm,
                        avg_unique_values, avg_information_content), decimals = 3)

# Export results
write_csv(variance_results, file.path(outputs_path, "variance_analysis_results.csv"))
write_csv(variance_summary, file.path(outputs_path, "feature_importance_rankings.csv"))
cat("Exported: variance analysis and feature importance rankings\n")
```


# 5. Field Importance Weighting

## 5.1 Field Scoring and Recommendations

```{r field_scoring}
# Combine all analysis results for scoring
field_scores <- field_quality_summary %>%
  select(field, field_type, avg_missing_rate, avg_cv) %>%
  # Add correlation metrics
  left_join(
    field_rankings %>%
      select(field1, avg_abs_correlation, high_correlations_count) %>%
      rename(field = field1, high_correlations = high_correlations_count),
    by = "field"
  ) %>%
  # Add variance metrics (including information content)
  left_join(
    variance_summary %>%
      select(field, avg_information_content),
    by = "field"
  ) %>%
  # Add quality issue counts
  left_join(
    issue_summary_by_field %>%
      select(field, avg_issues_per_dataset),
    by = "field"
  ) %>%
  # Replace NAs with appropriate values
  mutate(
    across(c(avg_missing_rate, avg_cv, avg_information_content,
            avg_abs_correlation, high_correlations,
            avg_issues_per_dataset), ~ coalesce(.x, 0))
  )

# Normalize scores to 0-1 scale
normalize_score <- function(x) {
  if (all(is.na(x)) || max(x, na.rm = TRUE) == min(x, na.rm = TRUE)) return(rep(0, length(x)))
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

field_scores <- field_scores %>%
  mutate(
    # Data Quality Scores (higher is better)
    completeness_score = normalize_score(1 - avg_missing_rate),
    variance_score = normalize_score(avg_cv),
    information_score = normalize_score(avg_information_content),

    # Correlation (lower correlation is better)
    uniqueness_score = normalize_score(-avg_abs_correlation),

    # Quality Issues (fewer issues is better)
    issue_penalty = normalize_score(-avg_issues_per_dataset),

    # Composite score (rebalanced without PCA)
    composite_score = (
      0.35 * completeness_score +      # Data completeness is crucial
      0.25 * information_score +       # Information content matters
      0.20 * variance_score +          # Variance indicates signal
      0.15 * uniqueness_score +        # Avoid redundant features
      0.05 * issue_penalty             # Penalize problematic fields
    )
  ) %>%
  arrange(desc(composite_score))

# Create recommendation categories
field_scores <- field_scores %>%
  mutate(
    recommendation = case_when(
      composite_score >= 0.7 ~ "High Priority - Include",
      composite_score >= 0.5 ~ "Medium Priority - Consider",
      composite_score >= 0.3 ~ "Low Priority - Evaluate",
      TRUE ~ "Consider Exclusion"
    )
  )

# Display scoring results
gt(field_scores %>% head(20) %>%
   select(field, field_type, composite_score, recommendation,
          completeness_score, information_score, variance_score)) %>%
  tab_header(title = "Field Importance Rankings (Top 20)") %>%
  fmt_number(columns = c(composite_score, completeness_score, information_score, variance_score),
             decimals = 3)

# Summary by recommendation category
recommendation_summary <- field_scores %>%
  count(recommendation, name = "field_count") %>%
  arrange(desc(field_count))

gt(recommendation_summary) %>%
  tab_header(title = "Field Recommendation Summary")

# Export scoring results
write_csv(field_scores, file.path(outputs_path, "field_importance_scores.csv"))
write_csv(recommendation_summary, file.path(outputs_path, "field_recommendation_summary.csv"))
cat("Exported: field importance scores and recommendations\n")
```

# 6. Dataset Quality Comparison

## 6.1 Basic Dataset Rankings

```{r dataset_comparison}
# Calculate basic dataset quality metrics
dataset_quality <- map_dfr(names(datasets), function(dataset_name) {
  df <- datasets[[dataset_name]]

  tibble(
    dataset = dataset_name,
    total_fields = ncol(df),
    total_rows = nrow(df),
    missing_rate = sum(is.na(df)) / (nrow(df) * ncol(df)),
    quality_score = (1 - missing_rate) * log10(total_rows) / 6  # Simple quality metric
  )
}) %>%
  arrange(desc(quality_score))

gt(dataset_quality) %>%
  tab_header(title = "Dataset Quality Rankings") %>%
  fmt_number(columns = c(missing_rate, quality_score), decimals = 3)

# Export dataset quality rankings
write_csv(dataset_quality, file.path(outputs_path, "dataset_quality_rankings.csv"))
cat("Exported: dataset quality rankings\n")
```

# 7. Summary and Recommendations

## 7.1 Key Findings Summary

```{r summary}
cat("=== TASK 2: DATA QUALITY VERIFICATION SUMMARY ===\n\n")

cat("DATASETS ANALYZED:", length(datasets), "\n")
cat("TOTAL UNIQUE FIELDS:", nrow(field_quality_summary), "\n")
cat("COMMON FIELDS ACROSS ALL DATASETS:", length(common_fields), "\n\n")

cat("FIELD RECOMMENDATIONS:\n")
if (exists("field_scores")) {
  rec_counts <- field_scores %>% count(recommendation)
  for (i in 1:nrow(rec_counts)) {
    cat("-", rec_counts$recommendation[i], ":", rec_counts$n[i], "fields\n")
  }
}

cat("\nTOP 5 RECOMMENDED FIELDS FOR MODELING:\n")
if (exists("field_scores")) {
  top_fields <- field_scores %>% head(5)
  for (i in 1:nrow(top_fields)) {
    cat(i, ".", top_fields$field[i],
        "(Score:", round(top_fields$composite_score[i], 3),
        "- Type:", top_fields$field_type[i], ")\n")
  }
}

cat("\nTOP 3 DATASETS FOR QUALITY:\n")
if (exists("dataset_quality")) {
  top_datasets <- dataset_quality %>% head(3)
  for (i in 1:nrow(top_datasets)) {
    cat(i, ".", top_datasets$dataset[i],
        "(Quality Score:", round(top_datasets$quality_score[i], 3), ")\n")
  }
}

cat("\nDATA QUALITY ISSUES SUMMARY:\n")
if (exists("issue_summary_by_field")) {
  total_issues <- sum(issue_summary_by_field$high_missing_datasets > 0)
  cat("- Fields with missing data issues:", total_issues, "\n")

  outlier_issues <- sum(issue_summary_by_field$excessive_outliers_datasets > 0)
  cat("- Fields with outlier issues:", outlier_issues, "\n")

  low_var_issues <- sum(issue_summary_by_field$low_variance_datasets > 0)
  cat("- Fields with low variance issues:", low_var_issues, "\n")
}

cat("\nEXPORTED ANALYSIS FILES:\n")
output_files <- list.files("outputs", pattern = "\\.csv$", full.names = FALSE)
for (file in output_files) {
  cat("- outputs/", file, "\n")
}
```

## 7.2 Final Dataset and Field Selection Decisions

Based on comprehensive analysis results, the following specific datasets and fields will be retained for modeling:

### DATASETS TO KEEP (7 datasets - 609 total records)

**Tier 1 - Primary Datasets (3 datasets - 509 records):**
1. **`access-to-health-care_national_zaf`** - 275 records (Quality Score: 0.346)
2. **`immunization_national_zaf`** - 116 records (Quality Score: 0.289)
3. **`hiv-behavior_national_zaf`** - 118 records (Quality Score: 0.278)

**Tier 2 - Secondary Datasets (4 datasets - 238 records):**
4. **`water_national_zaf`** - 100 records (Quality Score: 0.275)
5. **`dhs-quickstats_national_zaf`** - 52 records (Quality Score: 0.239)
6. **`toilet-facilities_national_zaf`** - 46 records (Quality Score: 0.228)
7. **`child-mortality-rates_national_zaf`** - 40 records (Quality Score: 0.223)

### DATASETS TO DROP (6 datasets - 298 total records)

**Rationale: Quality Score <0.20 or insufficient sample size:**
1. **`maternal-mortality_national_zaf`** - 21 records (Quality Score: 0.172) - Poorest quality, 21.8% missing rate
2. **`anthropometry_national_zaf`** - 37 records (Quality Score: 0.214) - Small sample, 18.0% missing rate
3. **`covid-19-prevention_national_zaf`** - 34 records (Quality Score: 0.210) - Small sample
4. **`symptoms-of-acute-respiratory-infection-ari_national_zaf`** - 26 records (Quality Score: 0.198) - Very small sample
5. **`iycf_national_zaf`** - 22 records (Quality Score: 0.184) - Very small sample
6. **`literacy_national_zaf`** - 20 records (Quality Score: 0.178) - Very small sample

### FIELDS TO KEEP (11 fields)

**Essential Fields (2 fields):**
- **`value`** (Score: 0.785) - Primary measurement values
- **`data_id`** (Score: 0.747) - Unique record identifier

**Core Analytical Fields (4 fields):**
- **`by_variable_id`** (Score: 0.634) - Important grouping variable
- **`precision`** (Score: 0.591) - Measurement precision indicator
- **`characteristic_order`** (Score: 0.579) - Demographic ordering
- **`indicator_order`** (Score: 0.573) - Indicator hierarchy

**Descriptive Fields (3 fields):**
- **`indicator`** (Score: 0.55) - Health indicator description
- **`indicator_type`** (Score: 0.55) - Indicator categorization
- **`characteristic_category`** (Score: 0.55) - Demographic categories

**Sample Size Field (1 field):**
- **`denominator_unweighted`** (Score: 0.531) - Unweighted sample sizes (categorical pattern)

**Quality Flag (1 field):**
- **`is_preferred`** (Score: 0.509) - Preferred estimate indicator

### FIELDS TO DROP (24 fields)

**Complete Exclusion (7 fields - Fatal quality issues):**
- **`region_id`** - 100% missing across all datasets
- **`level_rank`** - 100% missing across all datasets
- **`ci_low`** (categorical) - 100% missing in 10/13 datasets
- **`ci_high`** (categorical) - 100% missing in 10/13 datasets
- **`by_variable_label`** - 74% missing data
- **`ci_low`** (numeric) - 61% missing, limited availability
- **`ci_high`** (numeric) - 61% missing, limited availability

**Redundancy Removal (6 fields):**
- **`survey_year_label`** - Perfect duplicate of `survey_year` (r=1.0)
- **`denominator_weighted`** - Near-perfect correlation with `denominator_unweighted` (r=0.998)
- **`characteristic_id`** - High correlation with `characteristic_order`
- **`characteristic_label`** - Redundant with `characteristic_category`
- **`country_name`** - Constant value (South Africa)
- **`iso3`** - Constant value (ZAF)

**Low Priority Exclusion (11 fields):**
- **`survey_year`** - Low variance (same values across datasets)
- **`is_total`** - Low variance, minimal analytical value
- **`dhs_country_code`**, **`sdrid`**, **`survey_id`**, **`survey_type`** - Administrative fields
- **`indicator_id`** - Redundant with `indicator`

### Summary Statistics

**Final Dataset Composition:**
- **Total Records**: 609 (67% of original 907 records)
- **Total Fields**: 11 (35% of original 31 fields)
- **Average Missing Rate**: 16.8% (improvement from 18.1% overall)
- **Data Quality Score**: Weighted average of 0.271 (vs 0.229 for all datasets)

**Quality Improvements:**
- Eliminated 100% missing fields (4 fields)
- Removed high-missing datasets (6 datasets with <40 records or >20% missing)
- Eliminated perfect redundancies (6 field pairs)
- Retained high-information content fields (Score >0.5)

### Implementation for Task 3

**Data Cleaning Priorities:**
1. Load only the 7 selected datasets
2. Select only the 11 specified fields
3. Address outliers in `precision`, `value`, and `indicator_order` fields
4. Handle remaining missing data in `denominator_weighted`
5. Validate data types and ranges for all retained fields

```{r session_info}
sessionInfo()
```